{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Density Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angkor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# core\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import font_manager as fm\n",
    "import seaborn as sns\n",
    "import svgutils.transform as sg\n",
    "import cairosvg\n",
    "\n",
    "# chronocluster\n",
    "from chronocluster.data.dataio import pts_to_gis, kde_to_geotiff\n",
    "from chronocluster import clustering\n",
    "from chronocluster.utils import clustering_heatmap, pdiff_heatmap, get_box, chrono_plot, draw_ellipses\n",
    "from chronocluster.distributions import ddelta\n",
    "from chronocluster.density import kde_time, custom_kde, pymc_gmm_peak_finder, kde_peaks, rank_peaks\n",
    "from chronocluster.utils import plot_pdd\n",
    "\n",
    "# other utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic styling\n",
    "plt.style.use('ggplot')\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Load the Roboto font from its specific path\n",
    "#roboto_path = \"/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Regular.ttf\"\n",
    "#roboto_font = fm.FontProperties(fname=roboto_path)\n",
    "\n",
    "# matplotlib fonts\n",
    "#mpl.rcParams['font.family'] = 'Times'  # Change to your preferred font\n",
    "mpl.rcParams[\"font.size\"] = 12\n",
    "mpl.rcParams[\"legend.frameon\"] = False  # Remove legend background\n",
    "mpl.rcParams[\"legend.fontsize\"] = 10\n",
    "mpl.rcParams[\"axes.labelsize\"] = 12\n",
    "mpl.rcParams[\"axes.titlesize\"] = 14\n",
    "mpl.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "df = pd.read_csv('../Data/temples_with_predicted_ages.csv')\n",
    "df = df.dropna(subset=['xeast', 'ynorth', 'model_age_mean'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Points List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\n",
    "    clustering.Point(\n",
    "        x=row['xeast'],\n",
    "        y=row['ynorth'],\n",
    "        start_distribution = (\n",
    "            ddelta(d=row['model_age_mean']) \n",
    "            if row['model_age_sd'] == 0 \n",
    "            else norm(loc=row['model_age_mean'], scale=row['model_age_sd'])\n",
    "            ),\n",
    "        end_distribution = ddelta(1500)\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# just double check the first ten look right\n",
    "points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom styling parameters\n",
    "style_params = {\n",
    "    'start_mean_color': None,  # Do not plot start mean points\n",
    "    'end_mean_color': None, # Do not plot end mean points\n",
    "    'mean_point_size': 10,\n",
    "    'cylinder_color': (0.3, 0.3, 0.3),  # Dark grey\n",
    "    'ppf_limits': (0.05, 0.95),  # Use different ppf limits\n",
    "    'shadow_color': (0.4, 0.4, 0.4),  # grey\n",
    "    'shadow_size': 10,\n",
    "    'time_slice_color': (0.5, 0.5, 0.5),  # Grey\n",
    "    'time_slice_alpha': 0.3,\n",
    "    'time_slice_point_color': (0, 0, 0),  # Black\n",
    "}\n",
    "\n",
    "# Plot the points using the chrono_plot function with custom styling and a time slice plane\n",
    "ax_stv_angkor, fig_stv_angkor = chrono_plot(points, \n",
    "                                            style_params=style_params, \n",
    "                                            time_slice=1000,\n",
    "                                            title='Angkor')\n",
    "ax_stv_angkor.set_box_aspect(None, zoom=0.85)\n",
    "plt.savefig(\"../Output/spacetime_volume_Angkor.svg\", bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chronocluster.data import dataio\n",
    "from chronocluster.data.dataio import pts_to_gis\n",
    "\n",
    "pts_to_gis(points, output_path=\"angkor_points.gpkg\", epsg=32648)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Time Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time slices\n",
    "start_time = 800\n",
    "end_time = 1200\n",
    "time_interval = 50\n",
    "time_slices = np.arange(start_time, end_time, time_interval)\n",
    "time_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Boosted Pairwise Distance Density KDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import KernelDensity\n",
    "\n",
    "def cuml_kde(distances, bandwidth, **kwargs):\n",
    "    distances = np.array(distances).reshape(-1, 1)\n",
    "\n",
    "    if bandwidth is None:\n",
    "        n = len(distances)\n",
    "        if n < 2:\n",
    "            raise ValueError(\"Data must contain at least 2 points for bandwidth calculation.\")\n",
    "        std_dev = np.std(distances, ddof=1)  # Sample standard deviation\n",
    "        bandwidth = std_dev * n ** (-1 / 5)\n",
    "    \n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth, **kwargs)\n",
    "    kde.fit(distances)\n",
    "\n",
    "    def kde_function(points):\n",
    "        points = np.array(points).reshape(-1, 1)\n",
    "        # score_samples returns a cupy array; use .get() to convert to NumPy\n",
    "        return np.exp(kde.score_samples(points).get())  # Return densities as a NumPy array\n",
    "    \n",
    "    return kde_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Monte Carlo simulation to get an ensemble of probable \n",
    "# lists of points included in each time slice.\n",
    "num_iterations = 500 # sets the number of draws for incorporating chronological uncertainty\n",
    "simulations = clustering.mc_samples(points, \n",
    "                                    time_slices=time_slices,  \n",
    "                                    num_iterations=num_iterations)\n",
    "\n",
    "# Get a bounding box for use later and to extract sensible distance limits\n",
    "x_min, y_min, x_max, y_max = get_box(points)\n",
    "max_distance = np.ceil(np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2))\n",
    "\n",
    "# set consistent pairwise bandwidth (binning of distances)\n",
    "use_kde = True\n",
    "pair_bw = None\n",
    "kde_sample_n = 50\n",
    "kde_custom=cuml_kde\n",
    "\n",
    "# Produce pairwise distances to explore clustering structure\n",
    "pairwise_density, support = clustering.temporal_pairwise(simulations, \n",
    "                                                         time_slices,\n",
    "                                                         bw=pair_bw, \n",
    "                                                         use_kde=use_kde, \n",
    "                                                         kde_sample_n=kde_sample_n,\n",
    "                                                         max_distance=max_distance,\n",
    "                                                         kde_custom=kde_custom)\n",
    "\n",
    "# Visualize clustering with heatmap\n",
    "clustering_heatmap(pairwise_density,\n",
    "                   support,\n",
    "                   time_slices,\n",
    "                   result_type='Pairwise Distances',\n",
    "                   save = \"../Output/pdd_hm_angkor.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Spatial Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MC iterations for incorporating chronological uncertainty and CSR\n",
    "csr_simulations = clustering.mc_samples(points, \n",
    "                                        time_slices = time_slices,  \n",
    "                                        num_iterations = num_iterations,\n",
    "                                        null_model=clustering.csr_sample,\n",
    "                                        x_min=x_min, \n",
    "                                        x_max=x_max,\n",
    "                                        y_min=y_min, \n",
    "                                        y_max=y_max)\n",
    "\n",
    "# Calulate the pairwise distances for the CSR sample\n",
    "csr_pairwise_density, csr_support = clustering.temporal_pairwise(csr_simulations, \n",
    "                                                                 time_slices, \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Visualize clustering with heatmap\n",
    "clustering_heatmap(csr_pairwise_density,\n",
    "                   csr_support,\n",
    "                   time_slices,\n",
    "                   result_type='Pairwise Distances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for density differences between the observed points and \n",
    "# the simulated CSR baseline per distance and temporal slice\n",
    "p_diff_array, diff_array = clustering.p_diff(pairwise_density, csr_pairwise_density)\n",
    "\n",
    "# Plot the heatmap of probabilities\n",
    "pdiff_heatmap(p_diff_array,\n",
    "              time_slices,\n",
    "              csr_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline-Informed Spatial Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MC iterations for incorporating chronological uncertainty with BISE\n",
    "bise_simulations = clustering.mc_samples(points, \n",
    "                                         time_slices, \n",
    "                                         num_iterations=num_iterations,\n",
    "                                         null_model=clustering.bise)\n",
    "\n",
    "# Calulate the pairwise distances for the LISE sample\n",
    "bise_pairwise_density, bise_support = clustering.temporal_pairwise(bise_simulations, \n",
    "                                                                 time_slices, \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Calculate the p-values for density differences between the observed points and \n",
    "# the simulated CSR baseline per distance and temporal slice\n",
    "p_diff_array, diff_array = clustering.p_diff(pairwise_density, bise_pairwise_density)\n",
    "\n",
    "# Plot the heatmap of probabilities\n",
    "pdiff_heatmap(p_diff_array,\n",
    "              time_slices,\n",
    "              bise_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Time Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chronocluster.utils import plot_pdd\n",
    "\n",
    "time_slice_idx = np.where(time_slices == 1000)[0][0]  # corresponding to time 1100\n",
    "\n",
    "# List of density arrays\n",
    "density_arrays = [pairwise_density, csr_pairwise_density, bise_pairwise_density]\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig, ax = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Empirical\", \"CSR\", \"BISE\"],\n",
    "    colors=[\"blue\", \"orange\", \"green\"]\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of density arrays\n",
    "density_arrays = [diff_array]\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig, ax = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Diff Array\"],\n",
    "    colors=[\"blue\"]\n",
    ")\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series of Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of time_slice_idx values\n",
    "time_slice_indices = [0, 2, 4, 6]\n",
    "\n",
    "# Create a figure and axes for subplots\n",
    "num_panels = len(time_slice_indices)\n",
    "fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5), sharey=True)  # 1 row, multiple columns\n",
    "\n",
    "# Loop through each time_slice_idx and generate the plots\n",
    "for idx, (ax, time_slice_idx) in enumerate(zip(axes, time_slice_indices)):\n",
    "    # Generate the plot for the current time_slice_idx\n",
    "    fig, _ = plot_pdd(\n",
    "        time_slices=time_slices,\n",
    "        time_slice_idx=time_slice_idx,\n",
    "        support=support,\n",
    "        density_arrays=density_arrays,\n",
    "        quantiles=[0.025, 0.975],\n",
    "        density_names=[\"Diff Array\"],\n",
    "        colors=[\"blue\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Add a horizontal line (optional)\n",
    "    ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Add a title for each panel\n",
    "    ax.set_title(f\"Time Slice: {time_slices[time_slice_idx]}\")\n",
    "\n",
    "# Adjust layout and show the stitched plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid resolution and create the 2D grid for KDE evaluation\n",
    "# Get a bounding box for use later and to extract sensible distance limits\n",
    "x_min, y_min, x_max, y_max = get_box(points)\n",
    "max_distance = np.ceil(np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2))\n",
    "\n",
    "grid_resolution = 100  # Adjust the number of points as needed for resolution\n",
    "x_grid = np.linspace(x_min, x_max, grid_resolution)\n",
    "y_grid = np.linspace(y_min, y_max, grid_resolution)\n",
    "x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n",
    "grid = np.vstack([x_mesh.ravel(), y_mesh.ravel()]).T  # Flatten the grid for KDE input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporally-Weighted Spatial KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and save one or more characteristic scales\n",
    "characteristic_scales = [2500, 25000]\n",
    "\n",
    "# Set time_slice\n",
    "time_slice = time_slices[6]\n",
    "\n",
    "# Create a figure and axes for subplots\n",
    "num_panels = len(characteristic_scales)\n",
    "fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5), sharey=True)  # 1 row, multiple columns\n",
    "\n",
    "# Pre-calculate KDE values to determine the global color scale\n",
    "kde_values_list = []\n",
    "for characteristic_scale in characteristic_scales:\n",
    "    bandwidth =  characteristic_scale * 0.5\n",
    "    kde_values = kde_time(points, \n",
    "                          time_slice, \n",
    "                          bandwidth, \n",
    "                          grid, \n",
    "                          output_shape=x_mesh.shape, \n",
    "                          kde_method=custom_kde)\n",
    "    kde_values_list.append(kde_values)\n",
    "\n",
    "# Plot each kde using the shared color scale\n",
    "for i, (characteristic_scale, kde_values) in enumerate(zip(characteristic_scales, kde_values_list)):\n",
    "    # Plot KDE on the corresponding subplot\n",
    "    ax = axes[i]\n",
    "    contour = ax.contourf(x_mesh, y_mesh, kde_values, levels=20, cmap='viridis')\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.set_title(f\"Characteristic Scale: {characteristic_scale}\")\n",
    "\n",
    "    # Set scientific notation for both axes\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.xaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.yaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "\n",
    "    # Add individual colorbar for each plot\n",
    "    cbar = fig.colorbar(contour, ax=ax, orientation='horizontal', pad=0.15)\n",
    "    cbar.set_label(\"KDE Density\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series of Temporally-Weighted Spatial KDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bandwidth for spatial KDE\n",
    "bandwidth = characteristic_scales[0] * 0.5\n",
    "\n",
    "# Select the indices of the time slices you want to plot (4 slices)\n",
    "time_slice_indices = [0, 2, 4, 6]\n",
    "\n",
    "# Pre-calculate KDE values to determine the global color scale\n",
    "kde_values_list = []\n",
    "for time_slice_idx in time_slice_indices:\n",
    "    time_slice = time_slices[time_slice_idx]\n",
    "    kde_values = kde_time(points, \n",
    "                          time_slice, \n",
    "                          bandwidth, \n",
    "                          grid, \n",
    "                          output_shape=x_mesh.shape, \n",
    "                          kde_method=custom_kde)\n",
    "    kde_values_list.append(kde_values)\n",
    "\n",
    "# Determine global min and max for the color scale\n",
    "vmin = np.min([np.min(kde) for kde in kde_values_list])\n",
    "vmax = np.max([np.max(kde) for kde in kde_values_list])\n",
    "\n",
    "# Create subplots with 1 row and 4 columns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5), constrained_layout=True)\n",
    "\n",
    "# Plot each time slice using the shared color scale\n",
    "for i, (time_slice_idx, kde_values) in enumerate(zip(time_slice_indices, kde_values_list)):\n",
    "    time_slice = time_slices[time_slice_idx]\n",
    "    \n",
    "    # Plot KDE on the corresponding subplot\n",
    "    ax = axes[i]\n",
    "    contour = ax.contourf(x_mesh, y_mesh, kde_values, levels=20, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.set_title(f\"Time Slice {time_slice}\")\n",
    "\n",
    "    # Set scientific notation for both axes\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.xaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.yaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "\n",
    "# Add a single shared colorbar\n",
    "cbar = fig.colorbar(contour, ax=axes, orientation='horizontal', fraction=0.05, pad=0.1)\n",
    "cbar.set_label(\"KDE Density\")\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_to_geotiff(x_mesh, \n",
    "               y_mesh, \n",
    "               kde_values, \n",
    "               epsg_code=32648, \n",
    "               output_path=\"../Output/angkor_temples_kde_output.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved Angkor PDD Difference Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for spatial scale (variance) based on pairwise distance density analysis\n",
    "target_scale = characteristic_scales[0] * 0.5  # This is our target spatial scale for each component\n",
    "target_scale_sd = 1000  # Some variation around this value to reflect uncertainty\n",
    "\n",
    "# which corresponds to this portion of the PDD at the corresponding time slice\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig_pdd_angkor, ax_pdd_angkor = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Diff Array\"],\n",
    "    colors=[\"blue\"]\n",
    ")\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "ax_pdd_angkor.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_pdd_angkor.axvline(x=characteristic_scales[0], color = 'grey', linestyle='-', linewidth=1.5)\n",
    "ax_pdd_angkor.axvline(x=characteristic_scales[0] + target_scale_sd, color = 'grey', linestyle='--', linewidth=1.5)\n",
    "ax_pdd_angkor.axvline(x=characteristic_scales[0] - target_scale_sd, color = 'grey', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Save figure and close\n",
    "saved_fig_angkor = fig_pdd_angkor\n",
    "plt.close(fig_pdd_angkor)\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUNNO ABOUT WHETHER TO DO THE FOLLOWING FOR THIS PAPER OR LEAVE IT FOR ANOTHER PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify spatial density peaks\n",
    "# Calculate the spatial extent based on bounding box to constrain the prior for\n",
    "# the component means (parameter space outside this area is going to be fruitless)\n",
    "bounding_box_variance = ( max_distance / 2)**2\n",
    "\n",
    "# Set maximum number of components to allow in the model\n",
    "max_components = 8\n",
    "w_threshold = 1 / max_components # used for idenitifying peak importance\n",
    "\n",
    "# Run kde_peaks with GMM as the peak-finding method\n",
    "# Assuming coordinates is your dataset of temple locations, passed as Point objects\n",
    "peaks, weights, trace = kde_peaks(points=points, \n",
    "                                    num_peaks=max_components, \n",
    "                                    peak_finder=pymc_gmm_peak_finder,\n",
    "                                    time_slice = time_slice,\n",
    "                                    target_scale = target_scale,\n",
    "                                    target_scale_sd = target_scale_sd,\n",
    "                                    w_threshold = w_threshold,\n",
    "                                    sampler = 'NUTS',\n",
    "                                    draws = 2000,\n",
    "                                    tune = 4000,\n",
    "                                    chains = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_hdi = 0.80\n",
    "summary_df = rank_peaks(trace, significance=importance_hdi, source_param='importance')\n",
    "\n",
    "# isolate important peaks\n",
    "# Filter rows where the lower bound of the HDI is greater than importance_threshold\n",
    "importance_threshold = 0\n",
    "condition = summary_df[f'{int(importance_hdi * 100)}% HDI (Importance)'].apply(lambda hdi: hdi[0] > importance_threshold)\n",
    "important_peaks = summary_df[condition] # isloated for plotting below\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_df_to_gis(summary_df,\n",
    "              epsg_code=32648,\n",
    "              output_path=\"../Output/angkor_temple_cluster_centres.gpkg\", \n",
    "              file_format=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot KDE density surface\n",
    "ax.contourf(x_mesh, y_mesh, kde_values, levels=20, cmap='viridis')\n",
    "\n",
    "# Extract the X and Y coordinates from the Coordinates column for plotting\n",
    "x_coords = important_peaks['Coordinates'].apply(lambda coord: coord[0])\n",
    "y_coords = important_peaks['Coordinates'].apply(lambda coord: coord[1])\n",
    "\n",
    "# Plot the original data points\n",
    "#ax.scatter(summary_df['x'], summary_df['y'], color='white', marker='o', s=5, label='Original Data')\n",
    "\n",
    "# Draw ellipses for the GMM components with 1 SD and 2 SD ranges\n",
    "draw_ellipses(ax, \n",
    "              important_peaks, \n",
    "              std_devs=[1, 2], \n",
    "              edgecolor='red', \n",
    "              facecolor='none', \n",
    "              linestyle='--', \n",
    "              linewidth=1)\n",
    "\n",
    "# Annotate each component with its rank\n",
    "for x, y, rank in zip(x_coords, y_coords, important_peaks['Rank']):\n",
    "    ax.text(x, y, rank, color='black', ha='center', va='center', fontsize=12)\n",
    "\n",
    "# Add legend, labels, and title\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.set_title(\"KDE with GMM Peaks Ranked by Importance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hampshire County at Doomsday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "doomsday_places = pd.read_csv('../Data/doomsday_places.csv')\n",
    "doomsday_places = doomsday_places.dropna(subset=['easting', 'northing'])\n",
    "doomsday_places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes removing two problematic points in the data with a likely incorrect county labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating Hampshire for comparison with Angkor\n",
    "counties = ['HAM']\n",
    "doomsday_df = doomsday_places[doomsday_places['County'].isin(counties)]\n",
    "\n",
    "# I know there is a probable county designation error for the following point \n",
    "# (observed in QGIS as an kind of spatial outlier surrounded by points  with a \n",
    "# different designation and appears to be a duplicate point where the alternate \n",
    "# one has the same county designation as the other surrounding points)\n",
    "\n",
    "# PlacesIdx of the mislabelled point is 10221 while the alternate is 10226\n",
    "drop_idx = doomsday_df[doomsday_df['PlacesIdx'].isin([10221, 30086])].index\n",
    "doomsday_df = doomsday_df.drop(drop_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Points List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomsday_points = [\n",
    "    clustering.Point(\n",
    "        x=row['easting'],\n",
    "        y=row['northing'],\n",
    "        start_distribution = ddelta(1066),\n",
    "        end_distribution = ddelta(1086)\n",
    "    )\n",
    "    for _, row in doomsday_df.iterrows()\n",
    "]\n",
    "\n",
    "# just double check the first ten look right\n",
    "doomsday_points[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Time Slices and Spatial Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time slices\n",
    "start_time = 1066\n",
    "end_time = 1086\n",
    "time_interval = 5\n",
    "time_slices = np.arange(start_time, end_time, time_interval)\n",
    "time_slices\n",
    "\n",
    "# Get a bounding box for use later and to extract sensible distance limits\n",
    "x_min, y_min, x_max, y_max = get_box(doomsday_points)\n",
    "max_distance = np.ceil(np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom styling parameters\n",
    "style_params = {\n",
    "    'start_mean_color': None,  # Do not plot start mean points\n",
    "    'end_mean_color': None, # Do not plot end mean points\n",
    "    'mean_point_size': 10,\n",
    "    'cylinder_color': (0.3, 0.3, 0.3),  # Dark grey\n",
    "    'ppf_limits': (0.05, 0.95),  # Use different ppf limits\n",
    "    'shadow_color': (0.4, 0.4, 0.4),  # grey\n",
    "    'shadow_size': 10,\n",
    "    'time_slice_color': (0.5, 0.5, 0.5),  # Grey\n",
    "    'time_slice_alpha': 0.3,\n",
    "    'time_slice_point_color': (0, 0, 0),  # Black\n",
    "}\n",
    "\n",
    "# Plot the points using the chrono_plot function with custom styling and a time slice plane\n",
    "ax_stv_doomsday, fig_stv_doomsday = chrono_plot(doomsday_points, \n",
    "                                                style_params=style_params, \n",
    "                                                time_slice=1076,\n",
    "                                                title='Hamphsire')\n",
    "ax_stv_doomsday.set_box_aspect(None, zoom=0.85)\n",
    "plt.savefig(\"../Output/spacetime_volume_Hampshire.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SVG files\n",
    "fig1 = sg.fromfile(\"../Output/spacetime_volume_Angkor.svg\")\n",
    "fig2 = sg.fromfile(\"../Output/spacetime_volume_Hampshire.svg\")\n",
    "\n",
    "# Extract the plots as SVG elements\n",
    "plot1 = fig1.getroot()\n",
    "plot2 = fig2.getroot()\n",
    "\n",
    "# Get the width and height of the first and second plots\n",
    "fig1_width, fig1_height = fig1.get_size()\n",
    "fig2_width, fig2_height = fig2.get_size()\n",
    "\n",
    "# Convert dimensions to float for positioning and layout calculations\n",
    "fig1_width = float(fig1_width.replace(\"pt\", \"\"))\n",
    "fig1_height = float(fig1_height.replace(\"pt\", \"\"))\n",
    "fig2_width = float(fig2_width.replace(\"pt\", \"\"))\n",
    "fig2_height = float(fig2_height.replace(\"pt\", \"\"))\n",
    "\n",
    "# Calculate the combined width and maximum height\n",
    "combined_width = fig1_width + fig2_width\n",
    "combined_height = max(fig1_height, fig2_height)\n",
    "\n",
    "# Create a new SVG figure with the combined dimensions\n",
    "combined_fig = sg.SVGFigure(f\"{combined_width}px\", f\"{combined_height}px\")\n",
    "\n",
    "# Position the plots side by side\n",
    "plot1.moveto(0, 0)\n",
    "plot2.moveto(fig1_width, 0)\n",
    "\n",
    "# Append the plots to the combined figure\n",
    "combined_fig.append([plot1, plot2])\n",
    "\n",
    "# Save the combined figure\n",
    "combined_fig.save(\"../Output/spacetime_volume_combined.svg\")\n",
    "\n",
    "# convert and save as png\n",
    "# Convert the combined SVG to PNG with specified resolution\n",
    "cairosvg.svg2png(\n",
    "    url=\"../Output/spacetime_volume_combined.svg\",\n",
    "    write_to=\"../Output/spacetime_volume_combined.png\",\n",
    "    parent_width=combined_width,  # Set desired width in pixels\n",
    "    parent_height=combined_height  # Set desired height in pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Monte Carlo simulation to get an ensemble of probable \n",
    "# lists of points included in each time slice.\n",
    "simulations = clustering.mc_samples(doomsday_points, \n",
    "                                    time_slices=time_slices,  \n",
    "                                    num_iterations=num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling and Pairwise Distance Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a bounding box for use later and to extract sensible distance limits\n",
    "x_min, y_min, x_max, y_max = get_box(doomsday_points)\n",
    "max_distance = np.ceil(np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2))\n",
    "\n",
    "# set consistent pairwise bandwidth (binning of distances)\n",
    "# same as before with Angkor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce pairwise distances to explore clustering structure\n",
    "pairwise_density, support = clustering.temporal_pairwise(simulations, \n",
    "                                                         time_slices, \n",
    "                                                         bw=pair_bw, \n",
    "                                                         use_kde=use_kde, \n",
    "                                                         kde_sample_n=kde_sample_n,\n",
    "                                                         max_distance=max_distance,\n",
    "                                                         kde_custom=kde_custom)\n",
    "\n",
    "# Visualize clustering with heatmap\n",
    "clustering_heatmap(pairwise_density,\n",
    "                   support,\n",
    "                   time_slices,\n",
    "                   result_type='Pairwise Distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Spatial Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MC iterations for incorporating chronological uncertainty and CSR\n",
    "csr_simulations = clustering.mc_samples(doomsday_points, \n",
    "                                        time_slices = time_slices,  \n",
    "                                        num_iterations = num_iterations,\n",
    "                                        null_model=clustering.csr_sample,\n",
    "                                        x_min=x_min, \n",
    "                                        x_max=x_max,\n",
    "                                        y_min=y_min, \n",
    "                                        y_max=y_max)\n",
    "\n",
    "# Calulate the pairwise distances for the CSR sample\n",
    "csr_pairwise_density, csr_support = clustering.temporal_pairwise(csr_simulations, \n",
    "                                                                 time_slices, \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Visualize clustering with heatmap\n",
    "clustering_heatmap(csr_pairwise_density,\n",
    "                   csr_support,\n",
    "                   time_slices,\n",
    "                   result_type='Pairwise Distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline-Informed Spatial Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MC iterations for incorporating chronological uncertainty with BISE\n",
    "bise_simulations = clustering.mc_samples(doomsday_points, \n",
    "                                         time_slices, \n",
    "                                         num_iterations=num_iterations,\n",
    "                                         null_model=clustering.bise)\n",
    "\n",
    "# Calulate the pairwise distances for the LISE sample\n",
    "bise_pairwise_density, bise_support = clustering.temporal_pairwise(bise_simulations, \n",
    "                                                                 time_slices, \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Calculate the p-values for density differences between the observed points and \n",
    "# the simulated CSR baseline per distance and temporal slice\n",
    "p_diff_array, diff_array = clustering.p_diff(pairwise_density, bise_pairwise_density)\n",
    "\n",
    "# Plot the heatmap of probabilities\n",
    "pdiff_heatmap(p_diff_array,\n",
    "              time_slices,\n",
    "              bise_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Time Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chronocluster.utils import plot_pdd\n",
    "time_slice_idx = np.where(time_slices == 1066)[0][0]\n",
    "\n",
    "# List of density arrays\n",
    "density_arrays = [pairwise_density, csr_pairwise_density, bise_pairwise_density]\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig, ax = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Empirical\", \"CSR\", \"BISE\"],\n",
    "    colors=[\"blue\", \"orange\", \"green\"]\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of density arrays\n",
    "density_arrays = [diff_array]\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig, ax = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Diff Array\"],\n",
    "    colors=[\"blue\"]\n",
    ")\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporally-Weighted Spatial KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_resolution = 100  # Adjust the number of points as needed for resolution\n",
    "x_grid = np.linspace(x_min, x_max, grid_resolution)\n",
    "y_grid = np.linspace(y_min, y_max, grid_resolution)\n",
    "x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n",
    "grid = np.vstack([x_mesh.ravel(), y_mesh.ravel()]).T  # Flatten the grid for KDE input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and save one or more characteristic scales\n",
    "characteristic_scales = [3125, 60000]\n",
    "\n",
    "# Set time_slice\n",
    "time_slice = time_slices[time_slice_idx]\n",
    "\n",
    "# Create a figure and axes for subplots\n",
    "num_panels = len(characteristic_scales)\n",
    "fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5), sharey=True)  # 1 row, multiple columns\n",
    "\n",
    "# Pre-calculate KDE values to determine the global color scale\n",
    "kde_values_list = []\n",
    "for characteristic_scale in characteristic_scales:\n",
    "    bandwidth =  characteristic_scale * 0.5\n",
    "    kde_values = kde_time(doomsday_points, \n",
    "                          time_slice, \n",
    "                          bandwidth, \n",
    "                          grid, \n",
    "                          output_shape=x_mesh.shape, \n",
    "                          kde_method=custom_kde)\n",
    "    kde_values_list.append(kde_values)\n",
    "\n",
    "# Plot each kde using the shared color scale\n",
    "for i, (characteristic_scale, kde_values) in enumerate(zip(characteristic_scales, kde_values_list)):\n",
    "    # Plot KDE on the corresponding subplot\n",
    "    ax = axes[i]\n",
    "    contour = ax.contourf(x_mesh, y_mesh, kde_values, levels=20, cmap='viridis')\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.set_title(f\"Characteristic Scale: {characteristic_scale}\")\n",
    "\n",
    "    # Set scientific notation for both axes\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.xaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))\n",
    "    ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.yaxis.get_major_formatter().set_powerlimits((6, 6))\n",
    "\n",
    "    # Add individual colorbar for each plot\n",
    "    cbar = fig.colorbar(contour, ax=ax, orientation='horizontal', pad=0.15)\n",
    "    cbar.set_label(\"KDE Density\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save PDD Plot for Hampshire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for spatial scale (variance) based on pairwise distance density analysis\n",
    "target_scale = characteristic_scales[0] * 0.5  # This is our target spatial scale for each component\n",
    "target_scale_sd = 1000  # Some variation around this value to reflect uncertainty\n",
    "\n",
    "# which corresponds to this portion of the PDD at the corresponding time slice\n",
    "\n",
    "# Generate the plot and get the figure and axis objects\n",
    "fig_pdd_dooms, ax_pdd_dooms = plot_pdd(\n",
    "    time_slices=time_slices,\n",
    "    time_slice_idx=time_slice_idx,\n",
    "    support=support,\n",
    "    density_arrays=density_arrays,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    density_names=[\"Diff Array\"],\n",
    "    colors=[\"blue\"]\n",
    ")\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "ax_pdd_dooms.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_pdd_dooms.axvline(x=characteristic_scales[0], color = 'grey', linestyle='-', linewidth=1.5)\n",
    "ax_pdd_dooms.axvline(x=characteristic_scales[0] + target_scale_sd, color = 'grey', linestyle='--', linewidth=1.5)\n",
    "ax_pdd_dooms.axvline(x=characteristic_scales[0] - target_scale_sd, color = 'grey', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Save figure and close\n",
    "saved_fig_dooms = fig_pdd_dooms\n",
    "plt.close(fig_pdd_dooms)\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine PDD Time Slice Plots for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create a new figure for combining\n",
    "combined_pdd_fig = plt.figure(figsize=(12, 6))\n",
    "gs = GridSpec(1, 2, figure=combined_pdd_fig)\n",
    "\n",
    "# Add the first plot to the new figure\n",
    "ax_combined_1 = combined_pdd_fig.add_subplot(gs[0, 0])\n",
    "for line in saved_fig_angkor.axes[0].get_lines():\n",
    "    ax_combined_1.plot(line.get_xdata(), line.get_ydata(), color=line.get_color())\n",
    "ax_combined_1.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_combined_1.set_title(\"Angkor Pairwise Distance\")\n",
    "ax_combined_1.set_ylim([-4e-6, 4e-6])  # Set y-axis limits\n",
    "\n",
    "# Add the second plot\n",
    "ax_combined_2 = combined_pdd_fig.add_subplot(gs[0, 1])\n",
    "for line in saved_fig_dooms.axes[0].get_lines():\n",
    "    ax_combined_2.plot(line.get_xdata(), line.get_ydata(), color=line.get_color())\n",
    "ax_combined_2.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_combined_2.set_title(\"Hampshire (Domesday) Pairwise Distance\")\n",
    "ax_combined_2.set_ylim([-4e-6, 4e-6])  # Set y-axis limits\n",
    "\n",
    "# Display the combined figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled for Transportation Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Import NumPy for array manipulation\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Define the scaling ratio for the x-axis\n",
    "scaling_ratio = 1.5  # Example ratio, replace with your value\n",
    "\n",
    "# Create a new figure for combining\n",
    "combined_pdd_fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(2, 1, figure=combined_pdd_fig, height_ratios=[1, 1])\n",
    "\n",
    "# Add the first plot with scaled x-data\n",
    "ax_combined_1 = combined_pdd_fig.add_subplot(gs[0, 0])\n",
    "for line in saved_fig_angkor.axes[0].get_lines():\n",
    "    scaled_x = np.array(line.get_xdata()) * scaling_ratio  # Apply scaling\n",
    "    ax_combined_1.plot(scaled_x, line.get_ydata(), color=line.get_color())\n",
    "ax_combined_1.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_combined_1.set_title(\"Angkor Pairwise Distance (Scaled)\")\n",
    "ax_combined_1.set_ylim([-4e-6, 4e-6])  # Set y-axis limits\n",
    "\n",
    "# Add the second plot without scaling\n",
    "ax_combined_2 = combined_pdd_fig.add_subplot(gs[1, 0], sharex=ax_combined_1)  # Share x-axis with the first plot\n",
    "for line in saved_fig_dooms.axes[0].get_lines():\n",
    "    ax_combined_2.plot(line.get_xdata(), line.get_ydata(), color=line.get_color())\n",
    "ax_combined_2.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "ax_combined_2.set_title(\"Hampshire (Domesday) Pairwise Distance\")\n",
    "ax_combined_2.set_ylim([-4e-6, 4e-6])  # Set y-axis limits\n",
    "\n",
    "# Ensure the x-axis is labeled only at the bottom plot\n",
    "ax_combined_1.tick_params(labelbottom=False)  # Turn off x-axis labels for the top plot\n",
    "ax_combined_2.set_xlabel(\"Distance\")\n",
    "\n",
    "# Display the combined figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "\n",
    "def find_first_peak(pdd_slice, support):\n",
    "    \"\"\"\n",
    "    Finds the first peak in a PDD slice.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    pdd_slice : np.ndarray\n",
    "        A 1D array of PDD values for a single realization.\n",
    "    support : np.ndarray\n",
    "        Array of distance values (x-axis).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Distance (x-coordinate) of the first peak.\n",
    "    \"\"\"\n",
    "    # Find all peaks in the PDD slice\n",
    "    peaks, _ = find_peaks(pdd_slice)\n",
    "\n",
    "    # If peaks exist, return the first one\n",
    "    if len(peaks) > 0:\n",
    "        return support[peaks[0]]\n",
    "\n",
    "    # If no peaks are found, return NaN\n",
    "    return np.nan\n",
    "\n",
    "def find_all_first_peaks(diff_array, support, time_slice_idx):\n",
    "    \"\"\"\n",
    "    Finds the first peak for all realizations in a PDD difference array and returns \n",
    "    both the peak locations and their corresponding densities.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    diff_array : np.ndarray\n",
    "        3D array of PDD difference values (distances x time_slices x realizations).\n",
    "    support : np.ndarray\n",
    "        Array of distance values (x-axis).\n",
    "    time_slice_idx : int\n",
    "        Index of the time slice to analyze.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    peaks : list\n",
    "        List of first peak locations for all realizations.\n",
    "    densities : list\n",
    "        List of density values at the first peak for all realizations.\n",
    "    \"\"\"\n",
    "    peaks = []\n",
    "    densities = []\n",
    "    num_realizations = diff_array.shape[2]\n",
    "\n",
    "    for realization_idx in range(num_realizations):\n",
    "        # Extract the PDD slice for the current realization\n",
    "        pdd_slice = diff_array[:, time_slice_idx, realization_idx]\n",
    "\n",
    "        # Find the first peak location\n",
    "        peak_location = find_first_peak(pdd_slice, support)\n",
    "        \n",
    "        # if no peak, just return nan\n",
    "        if np.isnan(peak_location):\n",
    "            warnings.warn(\"No peak found.\", UserWarning)\n",
    "            peaks.append(np.nan)\n",
    "            densities.append(np.nan)\n",
    "        else:\n",
    "            # Get the density value at the peak\n",
    "            peak_density = pdd_slice[support == peak_location][0]  # Find density at the peak\n",
    "\n",
    "            # Append results\n",
    "            peaks.append(peak_location)\n",
    "            densities.append(peak_density)\n",
    "\n",
    "    return np.array(peaks), np.array(densities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Common Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 500 # sets the number of draws for incorporating chronological uncertainty\n",
    "# set consistent pairwise bandwidth (binning of distances)\n",
    "use_kde = True\n",
    "pair_bw = None\n",
    "kde_sample_n = 100\n",
    "kde_custom = cuml_kde\n",
    "max_distance = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angkor First Peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = 1100\n",
    "\n",
    "# Run the Monte Carlo simulation to get an ensemble of probable \n",
    "# lists of points included in each time slice.\n",
    "simulations = clustering.mc_samples(points, \n",
    "                                    time_slices=[time_slice],  \n",
    "                                    num_iterations=num_iterations)\n",
    "\n",
    "# Produce pairwise distances to explore clustering structure\n",
    "pairwise_density_angkor, support_angkor = clustering.temporal_pairwise(simulations, \n",
    "                                                         [time_slice],\n",
    "                                                         bw=pair_bw, \n",
    "                                                         use_kde=use_kde, \n",
    "                                                         kde_sample_n=kde_sample_n,\n",
    "                                                         max_distance=max_distance,\n",
    "                                                         kde_custom=kde_custom)\n",
    "\n",
    "# Get MC iterations for incorporating chronological uncertainty with BISE\n",
    "bise_simulations = clustering.mc_samples(points, \n",
    "                                         [time_slice], \n",
    "                                         num_iterations=num_iterations,\n",
    "                                         null_model=clustering.bise)\n",
    "\n",
    "# Calulate the pairwise distances for the LISE sample\n",
    "bise_pairwise_density_angkor, bise_support_angkor = clustering.temporal_pairwise(bise_simulations, \n",
    "                                                                 [time_slice], \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Calculate the p-values for density differences between the observed points and \n",
    "# the simulated CSR baseline per distance and temporal slice\n",
    "p_diff_array_angkor, diff_array_angkor = clustering.p_diff(pairwise_density_angkor, bise_pairwise_density_angkor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pdd_peaks_angkor, _ = find_all_first_peaks(diff_array_angkor, support_angkor, 0)\n",
    "\n",
    "# Convert to a Pandas DataFrame and use describe()\n",
    "summary_stats = pd.DataFrame(p_pdd_peaks_angkor, columns=[\"Values\"]).describe()\n",
    "\n",
    "# Display the summary statistics\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `peaks` is your data\n",
    "# Plot density and rug plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(p_pdd_peaks_angkor, color='blue', label=\"Density\")\n",
    "sns.rugplot(p_pdd_peaks_angkor, color='blue', alpha=0.5)  # Semi-transparent rug ticks\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"First Peak Location (Distance)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Distribution of First Peak Locations - Angkor at {time_slice}\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hampshire First Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = 1066\n",
    "\n",
    "# Run the Monte Carlo simulation to get an ensemble of probable \n",
    "# lists of points included in each time slice.\n",
    "simulations = clustering.mc_samples(doomsday_points, \n",
    "                                    time_slices=[time_slice],  \n",
    "                                    num_iterations=num_iterations)\n",
    "\n",
    "# Produce pairwise distances to explore clustering structure\n",
    "pairwise_density_hampshire, support_hampshire = clustering.temporal_pairwise(simulations, \n",
    "                                                         [time_slice],\n",
    "                                                         bw=pair_bw, \n",
    "                                                         use_kde=use_kde, \n",
    "                                                         kde_sample_n=kde_sample_n,\n",
    "                                                         max_distance=max_distance,\n",
    "                                                         kde_custom=kde_custom)\n",
    "\n",
    "# Get MC iterations for incorporating chronological uncertainty with BISE\n",
    "bise_simulations = clustering.mc_samples(doomsday_points, \n",
    "                                         [time_slice], \n",
    "                                         num_iterations=num_iterations,\n",
    "                                         null_model=clustering.bise)\n",
    "\n",
    "# Calulate the pairwise distances for the BISE sample\n",
    "bise_pairwise_density_hampshire, bise_support_hampshire = clustering.temporal_pairwise(bise_simulations, \n",
    "                                                                 [time_slice], \n",
    "                                                                 bw = pair_bw, \n",
    "                                                                 use_kde = use_kde,\n",
    "                                                                 kde_sample_n=kde_sample_n, \n",
    "                                                                 max_distance = max_distance,\n",
    "                                                                 kde_custom=kde_custom)\n",
    "\n",
    "# Calculate the p-values for density differences between the observed points and \n",
    "# the simulated CSR baseline per distance and temporal slice\n",
    "p_diff_array_hampshire, diff_array_hampshire = clustering.p_diff(pairwise_density_hampshire, bise_pairwise_density_hampshire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pdd_peaks_hampshire, _ = find_all_first_peaks(diff_array_hampshire, support_hampshire, 0)\n",
    "\n",
    "# Convert to a Pandas DataFrame and use describe()\n",
    "summary_stats = pd.DataFrame(p_pdd_peaks_hampshire, columns=[\"Values\"]).describe()\n",
    "\n",
    "# Display the summary statistics\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `peaks` is your data\n",
    "# Plot density and rug plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(p_pdd_peaks_hampshire, color='blue', label=\"Density\")\n",
    "sns.rugplot(p_pdd_peaks_hampshire, color='blue', alpha=0.5)  # Semi-transparent rug ticks\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"First Peak Location (Distance)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Distribution of First Peak Locations - Hampshire at {time_slice}\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `peaks` is your data\n",
    "# Plot density and rug plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(p_pdd_peaks_hampshire - p_pdd_peaks_angkor, color='blue', label=\"Density\")\n",
    "sns.rugplot(p_pdd_peaks_hampshire - p_pdd_peaks_angkor, color='blue', alpha=0.5)  # Semi-transparent rug ticks\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"First Peak Location Difference\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of First Peak Location Differences\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a Pandas DataFrame and use describe()\n",
    "summary_stats = pd.DataFrame(p_pdd_peaks_hampshire / p_pdd_peaks_angkor, columns=[\"Values\"]).describe()\n",
    "\n",
    "# Display the summary statistics\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `peaks` is your data\n",
    "# Plot density and rug plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(p_pdd_peaks_hampshire / p_pdd_peaks_angkor, color='blue', label=\"Density\")\n",
    "sns.rugplot(p_pdd_peaks_hampshire / p_pdd_peaks_angkor, color='blue', alpha=0.5)  # Semi-transparent rug ticks\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"First Peak Location Ratio\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of First Peak Location Ratios\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental\n",
    "Here we rerun the Domesday analysis but iterating over all counties listed in the 'County' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique list of counties\n",
    "counties = doomsday_places['County'].unique()\n",
    "\n",
    "# Ensure the Output directory exists\n",
    "output_dir = \"../Output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# loop over it\n",
    "for j in tqdm(counties, desc=\"Processing Counties\"):\n",
    "    # isolate j\n",
    "    doomsday_df = doomsday_places[doomsday_places['County'] == j]\n",
    "\n",
    "    # create list of points\n",
    "    doomsday_points = [\n",
    "    clustering.Point(\n",
    "        x=row['easting'],\n",
    "        y=row['northing'],\n",
    "        start_distribution = ddelta(1066),\n",
    "        end_distribution = ddelta(1086)\n",
    "    )\n",
    "    for _, row in doomsday_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Define the time slices\n",
    "    start_time = 1066\n",
    "    end_time = 1086\n",
    "    time_interval = 5\n",
    "    time_slices = np.arange(start_time, end_time, time_interval)\n",
    "    time_slices\n",
    "\n",
    "    # Get a bounding box for use later and to extract sensible distance limits\n",
    "    x_min, y_min, x_max, y_max = get_box(doomsday_points)\n",
    "    max_distance = np.ceil(np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2))\n",
    "\n",
    "    # Run the Monte Carlo simulation to get an ensemble of probable \n",
    "    # lists of points included in each time slice.\n",
    "    num_iterations = 500 # sets the number of draws for incorporating chronological uncertainty\n",
    "\n",
    "\n",
    "    # set consistent pairwise bandwidth (binning of distances)\n",
    "    use_kde = True\n",
    "    pair_bw = None\n",
    "    kde_sample_n = 50\n",
    "    kde_custom=cuml_kde\n",
    "\n",
    "    # Run the Monte Carlo simulation to get an ensemble of probable \n",
    "    # lists of points included in each time slice.\n",
    "    simulations = clustering.mc_samples(doomsday_points, \n",
    "                                        time_slices=time_slices,  \n",
    "                                        num_iterations=num_iterations)\n",
    "\n",
    "    # set consistent pairwise bandwidth (binning of distances)\n",
    "    # same as before with Angkor data\n",
    "    # Produce pairwise distances to explore clustering structure\n",
    "    pairwise_density, support = clustering.temporal_pairwise(simulations, \n",
    "                                                            time_slices, \n",
    "                                                            bw=pair_bw, \n",
    "                                                            use_kde=use_kde, \n",
    "                                                            kde_sample_n=kde_sample_n,\n",
    "                                                            max_distance=max_distance,\n",
    "                                                            kde_custom=kde_custom)\n",
    "    \n",
    "    # Get MC iterations for incorporating chronological uncertainty with BISE\n",
    "    bise_simulations = clustering.mc_samples(doomsday_points, \n",
    "                                            time_slices, \n",
    "                                            num_iterations=num_iterations,\n",
    "                                            null_model=clustering.bise)\n",
    "\n",
    "    # Calulate the pairwise distances for the LISE sample\n",
    "    bise_pairwise_density, bise_support = clustering.temporal_pairwise(bise_simulations, \n",
    "                                                                    time_slices, \n",
    "                                                                    bw = pair_bw, \n",
    "                                                                    use_kde = use_kde,\n",
    "                                                                    kde_sample_n=kde_sample_n, \n",
    "                                                                    max_distance = max_distance,\n",
    "                                                                    kde_custom=kde_custom)\n",
    "\n",
    "    # Calculate the p-values for density differences between the observed points and \n",
    "    # the simulated CSR baseline per distance and temporal slice\n",
    "    p_diff_array, diff_array = clustering.p_diff(pairwise_density, bise_pairwise_density)\n",
    "\n",
    "    #from chronocluster.utils import plot_pdd\n",
    "    time_slice_idx = np.where(time_slices == 1066)[0][0]\n",
    "\n",
    "    # List of density arrays\n",
    "    density_arrays = [diff_array]\n",
    "\n",
    "    # Generate the plot and get the figure and axis objects\n",
    "    fig, ax = plot_pdd(\n",
    "        time_slices=time_slices,\n",
    "        time_slice_idx=time_slice_idx,\n",
    "        support=support,\n",
    "        density_arrays=density_arrays,\n",
    "        quantiles=[0.025, 0.975],\n",
    "        density_names=[\"Diff Array\"],\n",
    "        colors=[\"blue\"]\n",
    "    )\n",
    "\n",
    "    # Add a horizontal line at y=0\n",
    "    ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "    # Save the plot to the Output directory\n",
    "    output_path = os.path.join(output_dir, f\"pdd_{j}.png\")\n",
    "\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
